<?xml version="1.0" encoding="utf-8"?>

<launch>

  <node name="HotwordRecogniser" pkg="tum_alle_athome_speech_hotword" type="hotword-detect.py" output="screen">
      <param name="hotword_model_tiago" value="$(find tum_alle_athome_speech_hotword)/resources/Tiago.pmdl"/>
      <param name="hotword_model_say" value="$(find tum_alle_athome_speech_hotword)/resources/Say.pmdl"/>
      <param name="hotword_model_move" value="$(find tum_alle_athome_speech_hotword)/resources/Move.pmdl"/>
      <param name="hotword_model_follow" value="$(find tum_alle_athome_speech_hotword)/resources/Follow.pmdl"/>
      <param name="hotword_model_bring" value="$(find tum_alle_athome_speech_hotword)/resources/Bring.pmdl"/>
      <param name="hotword_model_start" value="$(find tum_alle_athome_speech_hotword)/resources/Start.pmdl"/>
      <param name="hotword_model_wait" value="$(find tum_alle_athome_speech_hotword)/resources/Wait.pmdl"/>
      <param name="hotword_model_stop" value="$(find tum_alle_athome_speech_hotword)/resources/Stop.pmdl"/>
      <param name="commands_sensitivity" value="0.5"/>
      <param name="tiago_sensitivity" value="0.5"/>
      <!--param name="speech_recognition_srv" value="/tum_alle_athome_speech_recognition/speech_recog"/-->
      <param name="speech_recognition_srv" value="/planner"/>
  </node>

  <!-- <node name="test_speech" type="test_speech" pkg="test_speech" output="screen" /> -->
  <node name="speech_node" pkg="tum_alle_athome_speech_tts" type="text_to_speech.py" output="screen" />

  <node name="god_watcher" type="god_watcher" pkg="god_watcher" output="screen" />
  <node name="yolo_roi" type="yolo_roi" pkg="perception" output="screen" />
  <node name="depth2pointcloud" type="depth2pointcloud" pkg="perception" output="screen" />
  <node name="online_collecting" type="online_collecting" pkg="perception" output="screen" />
  <node name="online_learning" type="online_learning" pkg="perception" output="screen" />

  <!-- <node name="object_detection" type="object_detection" pkg="perception" output="screen" /> -->

  <node name="head_tracking" type="head_tracking" pkg="perception" output="screen" /> 

 <!--<node name="republish" type="republish" pkg="image_transport" output="screen" 	args="compressed in:=/front_camera/image_raw raw out:=/camera/image_raw" /> -->
 <!--node name="tracker" type="tracker" pkg="betracker" output="screen" 	args="-d $(find betracker)/src/tracking.cpp"/-->
  <arg name="rviz"     default="true"/>
 <arg name="public_sim"   default="false"/>
 <arg name="sim_sufix" value="_public_sim"     if="$(arg public_sim)"/>
  <arg name="sim_sufix" value=""                unless="$(arg public_sim)"/>

 <node name="rviz" pkg="rviz" type="rviz" if="$(arg rviz)"
          args="-d $(find tiago_2dnav)/config/rviz/navigation_public_sim.rviz"/>

  <node name="object_detection" type="object_detection" pkg="perception" output="screen"/>


  <!-- Load definition of pregrasp motion into play_motion namespace -->
  <rosparam command="load" file="$(find manipulation)/config/pick_motions.yaml" /> 

  <!-- Pick & place server -->
  <node name="pick_and_place_server" pkg="manipulation" type="pick_and_place_server.py" output="screen">
      <rosparam command="load" file="$(find manipulation)/config/pick_and_place_params.yaml" />
      <param name="object_width"  value="0.01" />
      <param name="object_height" value="0.06" />
      <param name="object_depth"  value="0.06" />
  </node>

  <!-- Node exposing service to start looking for the object and trigger the picking -->
  <node name="pick_client" pkg="manipulation" type="pick_client.py" output="screen"/>  

  <group if="$(arg rviz)">
      <node name="pick_demo_rviz" pkg="rviz" type="rviz" args="-d $(find manipulation)/config/rviz/tiago_pick_demo.rviz" />
  </group>

 <!--<node name="republish" type="republish" pkg="image_transport" output="screen"  args="compressed in:=/front_camera/image_raw raw out:=/camera/image_raw" /> -->
 <!--node name="tracker" type="tracker" pkg="betracker" output="screen"   args="-d $(find betracker)/src/tracking.cpp"/-->

</launch>

